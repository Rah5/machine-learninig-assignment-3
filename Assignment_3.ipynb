{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Simple Linear Regression\n",
        "1. What is Simple Linear Regression?\n",
        "Simple Linear Regression is a statistical method used to model the relationship between a dependent variable (Y) and a single independent variable (X) using a linear equation. It assumes that changes in the independent variable directly influence the dependent variable.\n",
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "Key assumptions include:\n",
        "- Linearity: The relationship between X and Y is linear.\n",
        "- Independence: Observations are independent.\n",
        "- Homoscedasticity: Constant variance in residuals.\n",
        "- Normality: Residuals follow a normal distribution.\n",
        "3. What does the coefficient m represent in the equation Y = mx + c?\n",
        "The coefficient m (slope) represents the rate of change in Y for every one-unit increase in X. A positive m indicates an increasing trend, while a negative m suggests a decreasing trend.\n",
        "4. What does the intercept c represent in the equation Y = mx + c?\n",
        "The intercept c is the value of Y when X = 0. It provides the baseline prediction in a regression model.\n",
        "5. How do we calculate the slope m in Simple Linear Regression?\n",
        "The slope m is calculated as:\n",
        "[ m = \\frac{\\sum (X_i - \\bar{X}) (Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2} ]\n",
        "This formula helps determine how X influences Y.\n",
        "6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        "The least squares method minimizes the sum of squared errors between observed and predicted values, ensuring the best-fit line for the given data.\n",
        "7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
        "R² measures how well the regression model explains the variability of Y. A higher R² value means better prediction accuracy.\n",
        "\n",
        "Multiple Linear Regression\n",
        "8. What is Multiple Linear Regression?\n",
        "Multiple Linear Regression extends Simple Linear Regression by modeling the relationship between a dependent variable and multiple independent variables, allowing for complex predictions.\n",
        "9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "Simple Linear Regression has one independent variable, while Multiple Linear Regression uses two or more independent variables.\n",
        "10. What are the key assumptions of Multiple Linear Regression?\n",
        "Same as Simple Linear Regression, plus:\n",
        "- No multicollinearity: Independent variables should not be highly correlated.\n",
        "- No autocorrelation: Errors should not be correlated across observations.\n",
        "11. What is heteroscedasticity, and how does it affect Multiple Linear Regression results?\n",
        "Heteroscedasticity occurs when residual variance is not constant, leading to unreliable coefficient estimates. It can be identified using residual plots.\n",
        "12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "Techniques include feature selection, Principal Component Analysis (PCA), and removing redundant variables.\n",
        "13. What are common techniques for transforming categorical variables for use in regression models?\n",
        "Methods include One-Hot Encoding, Label Encoding, and Binary Encoding.\n",
        "14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "Interaction terms model how two independent variables jointly influence the dependent variable.\n",
        "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "In Simple Regression, the intercept represents the baseline Y value when X = 0. In Multiple Regression, the intercept holds when all independent variables are set to zero.\n",
        "16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "A higher slope suggests stronger influence on Y, guiding better predictive insights.\n",
        "17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "The intercept sets a reference point for Y when independent variables hold their base values.\n",
        "18. What are the limitations of using R² as a sole measure of model performance?\n",
        "High R² does not mean better predictions—it can be misleading if overfitting exists.\n",
        "19. How would you interpret a large standard error for a regression coefficient?\n",
        "A large standard error indicates high variability in coefficient estimation, reducing reliability.\n",
        "20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "Heteroscedasticity appears as non-uniform spread in residual plots. Fixing it improves model accuracy.\n",
        "21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
        "It suggests that irrelevant variables are present in the model, reducing generalization ability.\n",
        "22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "Scaling ensures variables have equal influence on predictions, especially in gradient-based methods.\n",
        "\n",
        "Polynomial Regression\n",
        "23. What is polynomial regression?\n",
        "Polynomial regression extends linear regression by introducing higher-degree polynomial terms to better fit curved data trends.\n",
        "24. How does polynomial regression differ from linear regression?\n",
        "Linear regression fits straight lines, while polynomial regression fits curves to capture non-linear relationships.\n",
        "25. When is polynomial regression used?\n",
        "When data shows non-linear trends, polynomial regression provides better predictions than a straight line.\n",
        "26. What is the general equation for polynomial regression?\n",
        "[ Y = b_0 + b_1X + b_2Xn ]\n",
        "where n is the polynomial degree.\n",
        "27. Can polynomial regression be applied to multiple variables?\n",
        "Yes, by adding polynomial terms for each independent variable.\n",
        "28. What are the limitations of polynomial regression?\n",
        "Excessively high-degree polynomials may cause overfitting, reducing generalization.\n",
        "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "Using cross-validation, R², Adjusted R², and Mean Squared Error (MSE) to compare polynomial degrees.\n",
        "30. Why is visualization important in polynomial regression?\n",
        "Visualization helps assess if the fitted polynomial curve aligns well with data trends.\n",
        "31. How is polynomial regression implemented in Python?\n",
        "Using Scikit-Learn:\n"
      ],
      "metadata": {
        "id": "bv8sNw98ZjZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X = [[1], [2], [3], [4], [5]]\n",
        "y = [2, 4, 6, 8, 10]\n",
        "\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "print(\"Predicted values:\", model.predict(X_poly))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDcwts4sZqKh",
        "outputId": "8e4c57c4-20c5-4352-e8ab-d986a6694e2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted values: [ 2.  4.  6.  8. 10.]\n"
          ]
        }
      ]
    }
  ]
}